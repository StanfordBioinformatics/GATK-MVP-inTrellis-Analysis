{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trellis Neo4j: Coherence check results\n",
    "\n",
    "- DB for QC : PostgreSQL\n",
    "- Coherence check includes results generated by FastQC, Samtools Flagstat, and RTG Vcfstats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## 1.  Setup environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.cloud import storage\n",
    "import yaml\n",
    "\n",
    "from google.cloud import bigquery as bq\n",
    "#import google.datalab.bigquery as bq\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Storage bucket\n",
    "bucket_info = \"\"\n",
    "credential_info = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storage client\n",
    "storage_client = storage.Client()\n",
    "# get bucket with name\n",
    "bucket = storage_client.get_bucket(bucket_info)\n",
    "# get bucket data as blob\n",
    "blob = bucket.get_blob(credential_info)\n",
    "# convert to string\n",
    "yaml_data = blob.download_as_string()\n",
    "\n",
    "account = yaml.load(yaml_data, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(account[\"QC_DB_IP\"])\n",
    "#print(account[\"QC_DB_NAME\"])\n",
    "#print(account[\"QC_DB_USER\"])\n",
    "#print(account[\"QC_DB_PASSWORD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to databae\n",
    "conn = psycopg2.connect(\n",
    "                        host = account[\"QC_DB_IP\"],\n",
    "                        dbname = account[\"QC_DB_NAME\"],\n",
    "                        user = account[\"QC_DB_USER\"],\n",
    "                        password = account[\"QC_DB_PASSWORD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of fastqc records\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT sample, COUNT(*) from fastqc GROUP BY sample\")\n",
    "records = cursor.fetchall()\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of flagstat records\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT sample, COUNT(*) from flagstat GROUP BY sample\")\n",
    "records = cursor.fetchall()\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of vcfstats records\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT sample, COUNT(*) FROM vcfstats GROUP BY sample\")\n",
    "records = cursor.fetchall()\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of contamination records\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * from check_contamination\")\n",
    "records = cursor.fetchall()\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change list to dataframe for fastqc\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * from fastqc\")\n",
    "records = cursor.fetchall()\n",
    "fastqc_df=pd.DataFrame(records)\n",
    "fastqc_df.columns=['dimension','index','value','data','sample']\n",
    "fastqc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change list to dataframe for flagstat\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * from flagstat\")\n",
    "records = cursor.fetchall()\n",
    "flagstat_df=pd.DataFrame(records)\n",
    "flagstat_df.columns=['dimension','index','value','data','sample']\n",
    "flagstat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change list to dataframe for vcfstats\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * from vcfstats\")\n",
    "records = cursor.fetchall()\n",
    "vcfstats_df=pd.DataFrame(records)\n",
    "vcfstats_df.columns=['dimension','index','value','data','sample']\n",
    "vcfstats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change list to dataframe for contamination\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * from check_contamination\")\n",
    "records = cursor.fetchall()\n",
    "contam_df=pd.DataFrame(records)\n",
    "contam_df=contam_df[[0,6]]\n",
    "contam_df.columns=['sample','value']\n",
    "contam_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## 2.  Fastqc Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Base Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GC content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC content dataframe\n",
    "gc_df=fastqc_df.loc[fastqc_df['dimension']=='gc_content',['sample','value']]\n",
    "gc_df=gc_df.astype({'value': 'int64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "gc_df.drop_duplicates(subset=['sample'],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC mean\n",
    "gc_mean=gc_df.value.mean()\n",
    "print('Mean of GC content: {0:0.2f}'.format(gc_mean))\n",
    "\n",
    "# GC outlier\n",
    "gc_df['gc_outlier'] = gc_df.value.apply(lambda x: False if x in [40,41] else True)\n",
    "gc_outlier_df=gc_df[gc_df['gc_outlier']==True]\n",
    "num_gc_out=gc_outlier_df.gc_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of GC outliers: {0:0.2f}'.format(num_gc_out))\n",
    "gc_outlier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery without duplicated values\n",
    "bq_gc=gc_df.rename(columns={\"value\":\"gc\"})\n",
    "display(bq_gc.shape[0])\n",
    "bq_gc.set_index('sample',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "gc_df.value.hist(alpha=0.9, ax=ax, bins=10)\n",
    "ax.set_xlim(39,42)\n",
    "#ax.set_ylim(0,250)\n",
    "ax.set_title(\"Distribution of Reads GC Content by Genome\",size=15)\n",
    "ax.set_xlabel(\"GC Content (%)\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average sequence quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq qual dataframe\n",
    "seq_qual_df=fastqc_df.loc[fastqc_df['dimension']=='seq_quality',['sample','index','value']]\n",
    "seq_qual_df=seq_qual_df.astype({'index': 'int64','value':'float64'})\n",
    "seq_qual_df['tot_qual']=np.array(seq_qual_df['index'])*np.array(seq_qual_df['value'])\n",
    "seq_qual_df.head()\n",
    "\n",
    "# Average seq qual dataframe\n",
    "avg_df=seq_qual_df.groupby('sample').sum()\n",
    "avg_df['avg_seq_qual']=np.array(avg_df['tot_qual'])/np.array(avg_df['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average seq qual mean\n",
    "avg_mean=avg_df.avg_seq_qual.mean()\n",
    "avg_std=avg_df.avg_seq_qual.std()\n",
    "print('Mean of Average Seq Quality: {0:0.2f}'.format(avg_mean))\n",
    "print('Standard Diviation of Average Seq Quality: {0:0.2f}'.format(avg_std))\n",
    "\n",
    "# SNPS outlier\n",
    "avg_df['avg_seq_qual_outlier'] = avg_df.avg_seq_qual.apply(lambda x: False if x > 28 else True)\n",
    "avg_outlier_df=avg_df[avg_df['avg_seq_qual_outlier']==True]\n",
    "num_avg_out=avg_outlier_df.avg_seq_qual_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of Average Seq Quality outliers: {0:0.0f}'.format(num_avg_out))\n",
    "avg_outlier_df.head()\n",
    "#avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery without duplicated values\n",
    "bq_avg_seq_qual=avg_df[['avg_seq_qual','avg_seq_qual_outlier']]\n",
    "display(bq_avg_seq_qual.shape[0])\n",
    "bq_avg_seq_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average seq qual distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "avg_df.avg_seq_qual.hist(alpha=0.9, ax=ax)\n",
    "ax.set_xlim(27,30)\n",
    "ax.set_title(\"Distribution of Average Read Qualities\",size=15)\n",
    "ax.set_xlabel(\"Average Read Quality\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq Length dataframe\n",
    "seq_len_df=fastqc_df.loc[fastqc_df['dimension']=='seq_len',['sample','value']]\n",
    "seq_len_df=seq_len_df.astype({'value': 'int64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "seq_len_df.drop_duplicates(subset=['sample'],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique lengths\n",
    "seq_len_counts = seq_len_df.groupby('value')['sample'].nunique()\n",
    "print (seq_len_counts)\n",
    "\n",
    "# Seq_len outlier\n",
    "seq_len_df['seq_len_outlier'] = seq_len_df.value.apply(lambda x: False if x == 150 else True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery without duplicated values\n",
    "bq_seq_len=seq_len_df.loc[:,['sample','value','seq_len_outlier']].rename(columns={\"value\":\"seq_len\"})\n",
    "display(bq_seq_len.shape[0])\n",
    "bq_seq_len.set_index('sample',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq_len distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "bar = seq_len_counts.plot.bar(alpha=0.9)\n",
    "ax.set_title(\"Distribution of Read Lengths\")\n",
    "ax.set_xlabel(\"Read Length\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## 3.  RTG VCFstats Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe\n",
    "filter_df=vcfstats_df.loc[vcfstats_df['dimension'].isin(['failed_filters', 'passed_filters']),['dimension','sample','value']]\n",
    "filter_df=filter_df.astype({'value': 'int64'})\n",
    "filter_df.groupby('dimension')['value'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNPS dataframe\n",
    "snps_df=vcfstats_df.loc[vcfstats_df['dimension']=='snps',['sample','value']]\n",
    "snps_df=snps_df.astype({'value': 'int64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "snps_df.drop_duplicates(subset=['sample'],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNPS mean\n",
    "snps_mean=snps_df.value.mean()\n",
    "snps_std=snps_df.value.std()\n",
    "print('Mean of SNPS: {0:0.2f}'.format(snps_mean))\n",
    "print('Standard Diviation of SNPS: {0:0.2f}'.format(snps_std))\n",
    "\n",
    "# SNPS outlier\n",
    "snps_df['snps_outlier'] = snps_df.value.apply(lambda x: False if abs(snps_mean-x)<3*snps_std else True)\n",
    "snps_outlier_df=snps_df[snps_df['snps_outlier']==True]\n",
    "num_snps_out=snps_outlier_df.snps_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of SNPS outliers: {0:0.0f}'.format(num_snps_out))\n",
    "snps_outlier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery without duplicated samples\n",
    "bq_snps=snps_df.rename(columns={\"value\":\"snps\"})\n",
    "display(bq_snps.shape[0])\n",
    "bq_snps.set_index('sample',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNPS distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "hist = snps_df.value.hist(alpha=0.9, ax=ax, bins=20)\n",
    "ax.set_xlim(3000000,5500000)\n",
    "ax.set_title(\"Distribution of SNPs per Genome\",size=15)\n",
    "ax.set_xlabel(\"SNPs Count\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indels\n",
    "\n",
    "RTG Tools vcfstats outputs data on three categories of indels: insertions, deletions, and indels. From this google group post (https://groups.google.com/a/realtimegenomics.com/forum/#!searchin/rtg-users/vcfstats/rtg-users/-eFsSbWF6ks/1HrnevHTAgAJ):\n",
    "\n",
    ">For the insertions/deletions/indels the table is based on the delta in length rather than total length (which really matters for the indels):\n",
    "\n",
    ">Insertions (pure addition of bases)\n",
    ">A -> AT (length 1 insertion)\n",
    ">ATT -> ATTTT (length 2 insertion) \n",
    "\n",
    ">Deletions (pure deletion of bases)\n",
    ">AT -> A (length 1 deletion)\n",
    ">ATTTT -> ATT (length 2 deletion)\n",
    "\n",
    ">Indels (length changing but not pure)\n",
    ">ATT -> CTTT (length 1 indel)\n",
    ">CTTT -> ATT (length 1 indel)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indels dataframe\n",
    "pre_indels_df=vcfstats_df.loc[vcfstats_df['dimension'].isin(['indels','insertions','deletions']),['dimension','sample','value']]\n",
    "pre_indels_df=pre_indels_df.astype({'value': 'int64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "pre_indels_df.drop_duplicates(subset=['sample','dimension'],keep='first',inplace=True)\n",
    "\n",
    "# Accumulate all indels\n",
    "indels_df=pre_indels_df.groupby('sample')['value'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indels mean\n",
    "indels_mean=indels_df.value.mean()\n",
    "indels_std=indels_df.value.std()\n",
    "print('Mean of Indels: {0:0.2f}'.format(indels_mean))\n",
    "print('Standard Diviation of Indels: {0:0.2f}'.format(indels_std))\n",
    "\n",
    "# Indels outlier\n",
    "indels_df['indels_outlier'] = indels_df.value.apply(lambda x: False if abs(indels_mean-x)<3*indels_std else True)\n",
    "indels_outlier_df=indels_df[indels_df['indels_outlier']==True]\n",
    "num_indels_out=indels_outlier_df.indels_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of Indels outliers: {0:0.0f}'.format(num_indels_out))\n",
    "indels_outlier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery\n",
    "bq_indels=indels_df.rename(columns={\"value\":\"indels\"})\n",
    "bq_indels.set_index('sample',inplace=True)\n",
    "bq_indels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indels distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "hist = indels_df.value.hist(alpha=0.9, ax=ax, bins=40)\n",
    "ax.set_xlim(700000,1300000)\n",
    "ax.set_title(\"Distribution of Cumulative insertions, deletions, and indels\",size=15)\n",
    "ax.set_xlabel(\"Cumulative insertions, deletions, and indels Count\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ti/Tv ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ti/Tv dataframe\n",
    "titv_df=vcfstats_df.loc[vcfstats_df['dimension']=='ti_tv_ratio',['sample','value']]\n",
    "titv_df=titv_df.astype({'value': 'float64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "titv_df.drop_duplicates(subset=['sample'],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ti/Tv mean\n",
    "titv_mean=titv_df.value.mean()\n",
    "titv_std=titv_df.value.std()\n",
    "print('Mean of Ti/Tv ratio: {0:0.2f}'.format(titv_mean))\n",
    "print('Standard Diviation of Ti/Tv ratio: {0:0.2f}'.format(titv_std))\n",
    "\n",
    "# Indels outlier\n",
    "titv_df['titv_outlier'] = titv_df.value.apply(lambda x: False if abs(titv_mean-x)<3*titv_std else True)\n",
    "titv_outlier_df=titv_df[titv_df['titv_outlier']==True]\n",
    "num_titv_out=titv_outlier_df.titv_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of Ti/Tv ratio outliers: {0:0.0f}'.format(num_titv_out))\n",
    "titv_outlier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery without duplicated samples\n",
    "bq_titv=titv_df.rename(columns={\"value\":\"ti_tv\",\"titv_outlier\":\"ti_tv_outlier\"}).set_index('sample')\n",
    "display(bq_titv.shape[0])\n",
    "bq_titv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ti/Tv ratio distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "hist = titv_df.value.hist(alpha=0.9, ax=ax, bins=8)\n",
    "ax.set_xlim(1.85,2.0)\n",
    "ax.set_title(\"Distribution of Ti/Tv ratios\",size=15)\n",
    "ax.set_xlabel(\"Ti/Tv Ratio\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNP het/hom ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# het/hom dataframe\n",
    "hethom_df=vcfstats_df.loc[vcfstats_df['dimension']=='snp_het_hom_ratio',['sample','value']]\n",
    "hethom_df=hethom_df.astype({'value': 'float64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "hethom_df.drop_duplicates(subset=['sample'],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# het/hom mean\n",
    "hethom_mean=hethom_df.value.mean()\n",
    "hethom_std=hethom_df.value.std()\n",
    "print('Mean of SNP Het/Hom ratio: {0:0.2f}'.format(hethom_mean))\n",
    "print('Standard Diviation of SNP Het/Hom ratio: {0:0.2f}'.format(hethom_std))\n",
    "\n",
    "# het/hom outlier\n",
    "hethom_df['hethom_outlier'] = hethom_df.value.apply(lambda x: False if abs(hethom_mean-x)<3*hethom_std else True)\n",
    "hethom_outlier_df=hethom_df[hethom_df['hethom_outlier']==True]\n",
    "num_hethom_out=hethom_outlier_df.hethom_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of SNP Het/Hom ratio outliers: {0:0.0f}'.format(num_hethom_out))\n",
    "hethom_outlier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery\n",
    "bq_hethom=hethom_df.rename(columns={\"value\":\"het_hom\",\"hethom_outlier\":\"het_hom_outlier\"}).set_index('sample')\n",
    "display(bq_hethom.shape[0])\n",
    "bq_hethom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# het/hom ratio distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "hist = hethom_df.value.hist(alpha=0.9, ax=ax, bins=20)\n",
    "ax.set_title(\"Distribution of SNP het/hom ratios\",size=15)\n",
    "ax.set_xlabel(\"Het/Hom Ratio\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## 4.  Samtools Flagstat Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads mapped to reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total read dataframe\n",
    "total_cnt_df=flagstat_df.loc[flagstat_df['dimension']=='qc_passed_reads_count',['sample','value']]\n",
    "total_cnt_df=total_cnt_df.astype({'value': 'float64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "total_cnt_df.drop_duplicates(subset=['sample'],keep='first',inplace=True)\n",
    "display(total_cnt_df.shape[0])\n",
    "total_cnt_df=total_cnt_df.rename(columns={\"value\":\"total_cnt\"}).set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped read dataframe\n",
    "mapped_cnt_df=flagstat_df.loc[flagstat_df['dimension']=='mapped_reads_count',['sample','value']]\n",
    "mapped_cnt_df=mapped_cnt_df.astype({'value': 'float64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "mapped_cnt_df.drop_duplicates(subset=['sample','value'],keep='first',inplace=True)\n",
    "display(mapped_cnt_df.shape[0])\n",
    "\n",
    "mapped_cnt_df=mapped_cnt_df.rename(columns={\"value\":\"mapped_cnt\"}).set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped percent dataframe\n",
    "mapped_pct_df=total_cnt_df.join(mapped_cnt_df)\n",
    "mapped_pct_df['mapped_pct']=100*(mapped_pct_df['mapped_cnt']/mapped_pct_df['total_cnt'])\n",
    "mapped_pct_df['total_cnt']=mapped_pct_df.total_cnt.astype(int)\n",
    "mapped_pct_df['mapped_cnt']=mapped_pct_df.mapped_cnt.astype(int)\n",
    "mapped_pct_df['mapped_pct']=mapped_pct_df.mapped_pct.astype(float).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped percent mean and std\n",
    "mapped_pct_mean=mapped_pct_df.mapped_pct.mean()\n",
    "mapped_pct_std=mapped_pct_df.mapped_pct.std()\n",
    "\n",
    "print('Mean of the mapped read percentage : {0:0.2f}'.format(mapped_pct_mean))\n",
    "print('Standard Diviation of the mapped read percentage: {0:0.2f}'.format(mapped_pct_std))\n",
    "\n",
    "# mapped percent\n",
    "mapped_pct_df['mapped_pct_outlier'] = mapped_pct_df.mapped_pct.apply(lambda x: False if x > 98 else True)\n",
    "mapped_pct_outlier_df=mapped_pct_df[mapped_pct_df['mapped_pct_outlier']==True]\n",
    "num_mapped_pct_out=mapped_pct_outlier_df.mapped_pct_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of mapped read percentage outliers: {0:0.0f}'.format(num_mapped_pct_out))\n",
    "mapped_pct_outlier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery\n",
    "bq_mapped_pct=mapped_pct_df.loc[:,['mapped_pct','mapped_pct_outlier']]\n",
    "bq_mapped_pct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped read cnt distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "hist = mapped_pct_df.mapped_cnt.hist(alpha=0.9, ax=ax)\n",
    "ax.set_title(\"Distribution of Mapped Reads (Count)\",size=15)\n",
    "ax.set_xlabel(\"Count of Mapped Reads (Billions)\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped read pct distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "hist = mapped_pct_df.mapped_pct.hist(alpha=0.9, ax=ax)\n",
    "ax.set_title(\"Distribution of Mapped Reads (%)\",size=15)\n",
    "ax.set_xlabel(\"Percent Mapped Reads\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads properly paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly paired read dataframe\n",
    "paired_cnt_df=flagstat_df.loc[flagstat_df['dimension']=='properly_paired_count',['sample','value']]\n",
    "paired_cnt_df=paired_cnt_df.astype({'value': 'float64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "paired_cnt_df.drop_duplicates(subset=['sample'],keep='first',inplace=True)\n",
    "display(paired_cnt_df.shape[0])\n",
    "\n",
    "paired_cnt_df=paired_cnt_df.rename(columns={\"value\":\"paired_cnt\"}).set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly paired percent dataframe\n",
    "paired_pct_df=total_cnt_df.join(paired_cnt_df)\n",
    "paired_pct_df['paired_pct']=100*(paired_pct_df['paired_cnt']/paired_pct_df['total_cnt'])\n",
    "paired_pct_df['total_cnt']=paired_pct_df.total_cnt.astype(int)\n",
    "paired_pct_df['paired_cnt']=paired_pct_df.paired_cnt.astype(int)\n",
    "paired_pct_df['paired_pct']=paired_pct_df.paired_pct.astype(float).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly paired percent mean and std\n",
    "paired_pct_mean=paired_pct_df.paired_pct.mean()\n",
    "paired_pct_std=paired_pct_df.paired_pct.std()\n",
    "\n",
    "print('Mean of the properly paired read percentage : {0:0.2f}'.format(paired_pct_mean))\n",
    "print('Standard Diviation of the properly paired read percentage: {0:0.2f}'.format(paired_pct_std))\n",
    "\n",
    "# properly paired read percent outlier\n",
    "paired_pct_df['paired_pct_outlier'] = paired_pct_df.paired_pct.apply(lambda x: False if x > 95 else True)\n",
    "paired_pct_outlier_df=paired_pct_df[paired_pct_df['paired_pct_outlier']==True]\n",
    "num_paired_pct_out=paired_pct_outlier_df.paired_pct_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of properly paired read percentage outliers: {0:0.0f}'.format(num_paired_pct_out))\n",
    "paired_pct_outlier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery\n",
    "bq_paired_pct=paired_pct_df.loc[:,['paired_pct','paired_pct_outlier']]\n",
    "bq_paired_pct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly paired read cnt distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "hist = paired_pct_df.paired_cnt.hist(alpha=0.9, ax=ax)\n",
    "ax.set_title(\"Distribution of Properly Paired Reads (Count)\",size=15)\n",
    "ax.set_xlabel(\"Count of Properly Paired Reads (Billions)\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly paired read pct distribution\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "hist = paired_pct_df.paired_pct.hist(alpha=0.9, ax=ax)\n",
    "ax.set_title(\"Distribution of Properly Paired Reads (%)\",size=15)\n",
    "ax.set_xlabel(\"Percent Properly Paired Reads\",size=15)\n",
    "ax.set_ylabel(\"Frequency\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## 5. VerifyBamID Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check_contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_contamination dataframe\n",
    "contam_df=contam_df.astype({'value': 'float64'})\n",
    "\n",
    "# Remove duplicated samples\n",
    "contam_df.drop_duplicates(subset=['sample'],keep='first',inplace=True)\n",
    "display(contam_df.shape[0])\n",
    "\n",
    "contam_df=contam_df.rename(columns={\"value\":\"contam_rate\"}).set_index('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_contamination outlier\n",
    "contam_df.loc[contam_df.contam_rate < 0.05, 'contam_rate_outlier']=False\n",
    "contam_df.loc[contam_df.contam_rate >= 0.05, 'contam_rate_outlier']=True\n",
    "\n",
    "contam_outlier_df=contam_df[contam_df['contam_rate_outlier']==True]\n",
    "num_contam_out=contam_outlier_df.contam_rate_outlier.count()\n",
    "\n",
    "print('\\n'+'Number of contamination rate outliers: {0:0.0f}'.format(num_contam_out))\n",
    "contam_outlier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bigquery\n",
    "bq_contam=contam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_contamination box plot and distribution\n",
    "\n",
    "# Cut the window in 2 parts\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)}, figsize=(9,6))\n",
    " \n",
    "# Add a graph in each part\n",
    "sns.boxplot(contam_df[\"contam_rate\"], ax=ax_box)\n",
    "sns.distplot(contam_df[\"contam_rate\"], ax=ax_hist)\n",
    " \n",
    "# Remove x axis name for the boxplot\n",
    "ax_box.set(xlabel='')\n",
    "ax_box.set_title(\"Distribution of Contamination Rate (%)\",size=15)\n",
    "ax_hist.set_xlabel(\"Contamination Rate\",size=15)\n",
    "ax_hist.set_ylabel(\"Frequency\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## 6. Generate QC Bigquery table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(bq_gc.shape[0])\n",
    "# display(bq_seq_len.shape[0])\n",
    "# display(bq_snps.shape[0])\n",
    "# display(bq_indels.shape[0])\n",
    "# display(bq_titv.shape[0])\n",
    "# display(bq_hethom.shape[0])\n",
    "# display(bq_mapped_pct.shape[0])\n",
    "# display(bq_paired_pct.shape[0])\n",
    "# display(bq_contam.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bq_gc.head()\n",
    "#bq_seq_len.head()\n",
    "#bq_snps.head()\n",
    "#bq_indels.head()\n",
    "#bq_titv.head()\n",
    "#bq_hethom.head()\n",
    "#bq_mapped_pct.head()\n",
    "#bq_paired_pct.head()\n",
    "#bq_contam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all QC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_qc=bq_gc.merge(bq_avg_seq_qual, how='outer',left_index=True,right_index=True) \\\n",
    "     .merge(bq_seq_len, how='outer',left_index=True,right_index=True) \\\n",
    "     .merge(bq_snps, how='outer',left_index=True,right_index=True) \\\n",
    "     .merge(bq_indels, how='outer',left_index=True,right_index=True) \\\n",
    "     .merge(bq_titv, how='outer',left_index=True,right_index=True) \\\n",
    "     .merge(bq_hethom, how='outer',left_index=True,right_index=True) \\\n",
    "     .merge(bq_mapped_pct, how='outer',left_index=True,right_index=True) \\\n",
    "     .merge(bq_paired_pct, how='outer',left_index=True,right_index=True) \\\n",
    "     .merge(bq_contam, how='outer',left_index=True,right_index=True)\n",
    "bq_qc.reset_index(inplace=True)\n",
    "display(bq_qc.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add outlier list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pass\n",
    "bq_qc['outlier']='pass'\n",
    "\n",
    "## fail check\n",
    "bq_qc.loc[(bq_qc['gc_outlier']==True)|(bq_qc['avg_seq_qual_outlier']==True)|(bq_qc['seq_len_outlier']==True) \\\n",
    "          |(bq_qc['snps_outlier']==True)|(bq_qc['indels_outlier']==True)|(bq_qc['ti_tv_outlier']==True) \\\n",
    "          |(bq_qc['het_hom_outlier']==True)|(bq_qc['mapped_pct_outlier']==True)|(bq_qc['paired_pct_outlier']==True) \\\n",
    "          |(bq_qc['contam_rate_outlier']==True),'outlier']='outlier'\n",
    "\n",
    "## outlier\n",
    "bq_qc.loc[(bq_qc['gc_outlier'].isna())|(bq_qc['avg_seq_qual_outlier'].isna())|(bq_qc['seq_len_outlier'].isna()) \\\n",
    "          |(bq_qc['snps_outlier'].isna())|(bq_qc['indels_outlier'].isna())|(bq_qc['ti_tv_outlier'].isna()) \\\n",
    "          |(bq_qc['het_hom_outlier'].isna())|(bq_qc['mapped_pct_outlier'].isna())|(bq_qc['paired_pct_outlier'].isna()) \\\n",
    "          |(bq_qc['contam_rate_outlier'].isna()),'outlier']='uncompleted'\n",
    "\n",
    "bq_qc=bq_qc[['sample','outlier', 'gc', 'gc_outlier', 'avg_seq_qual', 'avg_seq_qual_outlier',\n",
    "       'seq_len', 'seq_len_outlier', 'snps', 'snps_outlier', 'indels',\n",
    "       'indels_outlier', 'ti_tv', 'ti_tv_outlier', 'het_hom',\n",
    "       'het_hom_outlier', 'mapped_pct', 'mapped_pct_outlier', 'paired_pct',\n",
    "       'paired_pct_outlier', 'contam_rate', 'contam_rate_outlier']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier and uncompleted lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_qc.loc[bq_qc['outlier']=='outlier',:].to_csv('gs://'+account['TRELLIS_BUCKET']+'/analysis-notebooks/qc_outlier.csv')\n",
    "bq_qc.loc[bq_qc['outlier']=='uncompleted',:].to_csv('gs://'+account['TRELLIS_BUCKET']+'/analysis-notebooks/qc_uncompleted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload DF to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id=account['BIGQUERY_DATASET']+'.qc_analysis'\n",
    "projectid=account['GOOGLE_CLOUD_PROJECT']\n",
    "\n",
    "pandas_gbq.to_gbq(\n",
    "    bq_qc, table_id, project_id=projectid, if_exists='replace',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_qc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
